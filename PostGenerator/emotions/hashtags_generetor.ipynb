{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3be94d",
   "metadata": {},
   "source": [
    "# Hashtags generator\n",
    "\n",
    "Ferramenta que deverá ser capaz de pegar no conteúdo das noticias em texto e produzir hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7661459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mariabarbosa/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1749046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Read the json files with de news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376ab859",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"../../../extractors/Snopes/extractions\")[0:1]:\n",
    "    with open(\"../../../extractors/Snopes/extractions/\" + file) as f:\n",
    "        data = json.load(f)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c365df1",
   "metadata": {},
   "source": [
    "### Modelos\n",
    "\n",
    "Verficar a utilizaçao de modelos já treinados para extrair keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52f2af",
   "metadata": {},
   "source": [
    "#### Using pre-trained language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e29072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "### https://pypi.org/project/keybert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06973c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/.local/lib/python3.8/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n",
      "  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n",
      "9it [00:00, 10.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('crowe', 0.3279),\n",
       "  ('maximus', 0.3426),\n",
       "  ('flying', 0.3439),\n",
       "  ('gladiator', 0.4291),\n",
       "  ('airplane', 0.4845)],\n",
       " [('endless', 0.2996),\n",
       "  ('article', 0.3202),\n",
       "  ('pages', 0.3332),\n",
       "  ('ad', 0.412),\n",
       "  ('slideshow', 0.5039)],\n",
       " [('biggest', 0.3259),\n",
       "  ('movie', 0.3331),\n",
       "  ('hide', 0.3378),\n",
       "  ('movies', 0.4488),\n",
       "  ('bloopers', 0.6852)],\n",
       " [('mistakes', 0.3608),\n",
       "  ('actors', 0.3949),\n",
       "  ('imperfections', 0.3968),\n",
       "  ('movies', 0.5057),\n",
       "  ('films', 0.5365)],\n",
       " [('misleading', 0.2373),\n",
       "  ('gadot', 0.298),\n",
       "  ('clickbait', 0.3363),\n",
       "  ('airplane', 0.3797),\n",
       "  ('gladiator', 0.3952)],\n",
       " [('movie', 0.202),\n",
       "  ('sky', 0.3056),\n",
       "  ('flying', 0.341),\n",
       "  ('airplane', 0.4392),\n",
       "  ('gladiator', 0.4851)],\n",
       " [('movie', 0.2619),\n",
       "  ('thumbnail', 0.2726),\n",
       "  ('fake', 0.3143),\n",
       "  ('youtube', 0.3207),\n",
       "  ('mistakes', 0.3351)],\n",
       " [('articles', 0.2499),\n",
       "  ('ad', 0.3087),\n",
       "  ('ads', 0.3662),\n",
       "  ('clickbait', 0.4219),\n",
       "  ('slideshow', 0.4429)],\n",
       " [('advertiser', 0.4064),\n",
       "  ('ads', 0.4548),\n",
       "  ('slideshow', 0.461),\n",
       "  ('advertising', 0.486),\n",
       "  ('advertisements', 0.5526)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text = data['postText']\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(original_text, keyphrase_ngram_range=(1, 1))\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702b97f",
   "metadata": {},
   "source": [
    "### KeyWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe00dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sentence):\n",
    "    \n",
    "        stop = set(stopwords.words('english')) #define stop words\n",
    "        exclude = set(string.punctuation) #define ponctuation for exclude\n",
    "        lemma = WordNetLemmatizer() \n",
    "        \n",
    "        stop_free = \" \".join([i for i in sentence.lower().split() if i not in stop])\n",
    "        punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split()) ##lematizar\n",
    "        return normalized\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5797630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentimentAnalysis\n",
    "\n",
    "def sentiment_analysis(text, language):  \n",
    "    \n",
    "    status_code = 0 ## Valor inicial \n",
    "    \n",
    "    while (status_code != 200):\n",
    "        emotions, status_code = sentimentAnalysis.main(text,language)\n",
    "    playload_emotions = json.loads(emotions)\n",
    "    \n",
    "    return playload_emotions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2908328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtags_check_emotion(hashtaglist):\n",
    "        ## call the module of sentiment analysis\n",
    "        playload_emotions  = playload = sentiment_analysis(hashtaglist,'en')\n",
    "   \n",
    "        sortedByEmotion = {k: v for k, v in sorted(playload_emotions.items(), key=lambda item: (item[1]['emotions']['sadness'] + item[1]['emotions']['surprise'] + item[1]['emotions']['trust'] + item[1]['emotions']['anger'] + item[1]['emotions']['disgust'] + item[1]['emotions']['fear'] + item[1]['emotions']['joy']), reverse=True)}\n",
    "       # print(sortedByEmotion)\n",
    "        playload = [] ## add only the hashtags with some percentage of emotion\n",
    "        \n",
    "        \n",
    "        for hashtag, emotion in sortedByEmotion.items():\n",
    "            if (emotion['emotions']['sadness'] + emotion['emotions']['surprise'] + emotion['emotions']['trust'] + emotion['emotions']['anger'] + emotion['emotions']['disgust'] + emotion['emotions']['fear'] + emotion['emotions']['joy']) > 0:\n",
    "                #print((emotion['emotions']['sadness'] + emotion['emotions']['surprise'] + emotion['emotions']['trust'] + emotion['emotions']['anger'] + emotion['emotions']['disgust'] + emotion['emotions']['fear'] + emotion['emotions']['joy']) > 0)\n",
    "                playload.append(hashtag)\n",
    "                \n",
    "        return (playload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0ba9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keyphrase_vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ebc717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 11:17:14.572201: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-28 11:17:14.572243: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from keybert import KeyBERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db09e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generateHashtags (text):\n",
    "    topicsNun = 6\n",
    "    passes = 50\n",
    "    \n",
    "   # text = ' '.join(data['postText']).split('\\n')\n",
    "\n",
    "    text_clean = []\n",
    "    for sentence in text:\n",
    "        d = clean(sentence).split()\n",
    "        text_clean.append(d)\n",
    "\n",
    "    text_clean = [clean(sentence).split() for sentence in text]   \n",
    "\n",
    "    dictionary = corpora.Dictionary(text_clean)\n",
    "    \n",
    "    matrix = [dictionary.doc2bow(sentence) for sentence in text_clean]\n",
    "    \n",
    "    #Define the LDA model\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "    ldamodel = Lda(matrix, num_topics=topicsNun, id2word = dictionary, passes=passes)\n",
    "    #extract topics\n",
    "    topic = ldamodel.print_topics(num_topics=topicsNun, num_words=5)\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    ##Identify the keywords defined in the topics\n",
    "    hashtags = []\n",
    "    \n",
    "    for t in topic:\n",
    "        for h in t[1].split('+'):    \n",
    "            hashtags.append(h[h.find('\"')+1:h.rfind('\"')])\n",
    "    \n",
    "    print(\"HashTags sugestion: \", list(set(hashtags)))\n",
    "    \n",
    "    \n",
    "  #  kw_model = KeyBERT()\n",
    "    \n",
    "   # print(\"HashTags sugestion BERT: \", kw_model.extract_keywords(docs=text, keyphrase_ngram_range=(1,2)))\n",
    "    \n",
    "   \n",
    "  #  print(\"HashTags sugestion BERT w/ vectorizer \", kw_model.extract_keywords(docs=text, vectorizer=KeyphraseCountVectorizer()))\n",
    "\n",
    "    playload = hashtags_check_emotion (list(set(hashtags)))\n",
    "\n",
    "    return (playload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca3edf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashTags sugestion:  ['twitter’s', 'account', 'rule', 'rumor', 'social', 'control', 'twitter', 'risk', 'musk', 'trump', '“due', 'medium', 'service', 'put']\n",
      "['account', 'rule', 'rumor', 'trump', 'risk']\n",
      "Twitter’s ban on former U.S. President Donald Trump was reversed in April 2022 by Elon Musk. \n",
      "\n",
      "false\n",
      "https://www.snopes.com/fact-check/musk-reinstate-trump-on-twitter/\n"
     ]
    }
   ],
   "source": [
    "hashtags = generateHashtags(' '.join(data['postText']).split('\\n'))\n",
    "print(hashtags)\n",
    "print(data['allegation'])\n",
    "print(data['evaluation'])\n",
    "print(data['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c0a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "216617d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashTags sugestion:  ['misleading', 'film', 'airplane', 'article', 'page', 'often', 'ad', 'movie', 'slideshow', '“gladiator”']\n",
      "alegation  An airplane is visible in a scene in the movie “Gladiator,” which was set in ancient Rome.\n",
      " hashtags:  ['“gladiator”', 'misleading']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['exchange', 'feature', 'several', 'twitter', 'swastika', 'nein…', 'emoji', 'pulling', 'branding', 'like', 'new', 'binance', 'symbol']\n",
      "alegation  Cryptocurrency exchange company Binance briefly used a Twitter emoji that looked like a swastika.\n",
      " hashtags:  ['exchange']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['twitter', 'rumor', 'put', 'service', 'medium', 'rule', 'musk', 'social', 'account', 'risk']\n",
      "alegation  Twitter’s ban on former U.S. President Donald Trump was reversed in April 2022 by Elon Musk. \n",
      " hashtags:  ['account', 'rule', 'rumor', 'risk']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['account', 'remained', 'ban', 'posted', 'propaganda', 'intern', 'social', 'take', 'onion', 'twitter', 'banned']\n",
      "alegation  The Twitter account for the parody news site The Onion has been banned from Twitter.\n",
      " hashtags:  ['account']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['kenya', 'misleading', 'basigo', 'fire', 'electric', 'road', 'karen', 'bus', 'video']\n",
      "alegation  A video shows an electric-powered BasiGo bus bursting into flames on Karen Road in Kenya.\n",
      " hashtags:  ['electric', 'fire', 'misleading']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['entry', 'list', 'record', 'available', 'communication', 'document', 'information', 'request', 'fbi']\n",
      "alegation  The FBI compiled an internal 83-page document on internet slang that they released in 2014.\n",
      " hashtags:  ['communication']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['project', 'eye', 'kamburov', 'microscope', 'dog', 'video', 'world', 'one']\n",
      "alegation  A video shows what a hot dog looks like under a microscope. \n",
      " hashtags:  ['microscope']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['court', 'baby', 'hardcastle', 'family', 'judge', 'beanie', 'one', 'couple']\n",
      "alegation  A photograph shared widely in April 2022 showed a divorced couple dividing up their Beanie Babies on the floor of a courtroom. \n",
      " hashtags:  ['baby', 'court']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['mathematics', 'florida', 'textbook', 'rejected', 'also', 'crt', 'core', 'race', 'department']\n",
      "alegation  Florida has rejected a number of mathematics textbooks on the basis that they allegedly reference critical race theory (CRT).\n",
      " hashtags:  ['rejected']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['u', '—', 'cain', 'kelly', 'black', 'host', 'shapiro']\n",
      "alegation  In April 2022, Newsmax aired images of four people — Sheriff David Clarke, Herman Cain, Ben Shapiro, and Ben Carson — above a chyron that read, “LEFT CONSIDERS BLACK CONSERVATIVES TO BE TRAITORS.”\n",
      " hashtags:  ['black']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['reflect', 'mar', 'article', 'candy', 'change', 'green', 'snicker', 'news', 'bar']\n",
      "alegation  In April 2022, Mars started making Snickers bars without the “vein” after people complained that the chocolate bars too closely resembled a penis. \n",
      " hashtags:  ['change', 'green']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['spm', 'man', 'case', 'sexual', 'emergency', 'report']\n",
      "alegation  A 20-year-old man “masturbated so hard” that he ruptured a lung and required hospitalization in an intensive care unit.\n",
      " hashtags:  ['case', 'emergency']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['train', 'cause', 'people', 'meme', 'angeles', 'los', 'crash']\n",
      "alegation  A man was sentenced to 11 consecutive life sentences after abandoning his vehicle on train tracks near Los Angeles in a suicide attempt, resulting in a train crash that killed 11.\n",
      " hashtags:  ['crash']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['source', 'church', 'street', 'light', 'lighting', 'meme', 'papal', 'pope', 'gas']\n",
      "alegation  The Catholic church once formally opposed street lights for religious reasons, and Pope Gregory XVI banned gas lighting.\n",
      " hashtags:  ['church']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['letter', 'president', 'cover', 'time', 'fake', 'symbol', 'zelenskyy']\n",
      "alegation  An image shows a genuine Time magazine cover featuring “Ladimir Elensky,” omitting the letters “V” and “Z” in Volodymyr Zelenskyy’s name.\n",
      " hashtags:  ['cover', 'president']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['it’s', 'word', 'medium', 'washington', 'social', 'quote', 'account']\n",
      "alegation  Actor Denzel Washington once said: “Just because you don’t share it on social media doesn’t mean you are not up to big things. Live it and stay low key. Privacy is everything.”\n",
      " hashtags:  ['account', 'word', 'quote']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['berling', '—', 'gravity', 'birthday', 'party', 'diagnostics']\n",
      "alegation  Kevin Berling sued his former employer, Gravity Diagnostics, for throwing a workplace birthday party that he did not want.\n",
      " hashtags:  ['birthday']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['momsen', 'an', '2009', 'nike', 'advertisement', 'video', 'viral']\n",
      "alegation  A video shows singer Taylor Momsen using parkour to escape from paparazzi in real life. \n",
      " hashtags:  []\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['ring', 'conspiracy', 'pedophile', 'gibson', 'quote', 'theory', 'fake']\n",
      "alegation  Actor Mel Gibson said “Hollywood is an institutionalized pedophile ring.”\n",
      " hashtags:  ['conspiracy', 'quote', 'theory']\n",
      "\n",
      "\n",
      "HashTags sugestion:  ['sea', 'peta', '“sea', 'kitten', 'website', 'campaign', 'fish', 'one']\n",
      "alegation  People for the Ethical Treatment of Animals (PETA) renamed fish “sea kittens.” \n",
      " hashtags:  ['kitten']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"extractors/Snopes/extractions\")[:20]:\n",
    "    with open(\"extractors/Snopes/extractions/\" + file) as f:\n",
    "        data = json.load(f)\n",
    "        hashtags = generateHashtags(' '.join(data['postText']).split('\\n'))\n",
    "        print('alegation ',data['allegation'] ,'hashtags: ', hashtags)\n",
    "        print('\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914978d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
