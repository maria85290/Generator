{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4abe034c",
   "metadata": {},
   "source": [
    "# Generator V2\n",
    "\n",
    "Ferramenta que pega no conteudo das noticias (em formato json) e gera posts.\n",
    "\n",
    "O tweet tem os seguintes elementos: \n",
    "* Alegação;\n",
    "* Classificação;\n",
    "* Hashtags relevantes;\n",
    "* Emojis;\n",
    "* URL;\n",
    "\n",
    "### Os elementos do tweet TEM aletoriedade:\n",
    "Baseia-se nas seguintes regras:\n",
    "\n",
    "        1) Tem URL;\n",
    "        2) Tem alegaçao;\n",
    "        3) Tem avaliçao;\n",
    "        4) tem/não tem emojies;\n",
    "        5) tem/não hashtags;\n",
    "        6) Introduz ou não interjections;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "544627d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mariabarbosa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/mariabarbosa/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "from keybert import KeyBERT\n",
    "import emoji #https://carpedm20.github.io/emoji/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5b8e1",
   "metadata": {},
   "source": [
    "### Gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5204caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install import-ipynb\n",
    "import hashtags_generetor\n",
    "import emojis\n",
    "import verify_post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bfac3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_capslock_allegation(data):\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', data['allegation']) \n",
    "    words_allegation = [word.lower() for word in text.strip('\\n').split() ]\n",
    "    \n",
    "    \n",
    "    ## Definir o modelo\n",
    "    kw_model = KeyBERT()\n",
    "    words_bert = [word for word, value in kw_model.extract_keywords(docs=text, keyphrase_ngram_range=(1,1))]\n",
    "                                        \n",
    "    allegation =  []\n",
    "    \n",
    "    for word in text.strip('\\n').split():\n",
    "        if word.lower() in words_bert:\n",
    "            allegation.append(word.upper())\n",
    "        else:\n",
    "            allegation.append(word)\n",
    "    \n",
    "    allegation = ' '.join(allegation)\n",
    "    post = []\n",
    "\n",
    "    #emoji.emojize(':thumbs_up:')\n",
    "    post.append(allegation)\n",
    "    #+ choice(dic[data['evaluation']])\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71ef46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interjections (evaluation):\n",
    "    with open('../corpus/interjections.json') as f:\n",
    "        interjection = json.load(f)\n",
    "        if evaluation == \"true\":\n",
    "            l = random.choice (interjection[\"true\"])\n",
    "        else:\n",
    "            l = random.choice (interjection[\"fake\"])\n",
    "        return l\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "578dac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    posts = {}\n",
    "    ##### Read the json files with de news\n",
    "    for file in os.listdir(\"../../extractors/Snopes/exemplo\"):\n",
    "        with open(\"../../extractors/Snopes/exemplo/\" + file) as f:\n",
    "            data = json.load(f)\n",
    "            f.close()\n",
    "            \n",
    "        post = generate_capslock_allegation(data)\n",
    "      #  if (verify_post.verify_length(' '.join (post)) == False):\n",
    "      #      post = post[:280]\n",
    "\n",
    "\n",
    "        s = random.randint(0,3)\n",
    "        if s == 0:\n",
    "          post.append( emoji.emojize(':red_exclamation_mark:') + data['evaluation'].upper() + emoji.emojize(':red_exclamation_mark:'))\n",
    "        elif s==1 :\n",
    "           post.append( data['evaluation'].upper())\n",
    "        else:\n",
    "          post.append( data['evaluation'].upper() + emoji.emojize(':red_exclamation_mark:') * random.randint(0,6) )\n",
    "        \n",
    "        '''\n",
    "        Introduzir aleatoriedade;\n",
    "        '''\n",
    "       \n",
    "        hashtags = hashtags_generetor.generateHashtags(' '.join(data['postText']).split('\\n'))\n",
    "        \n",
    "\n",
    "        hashtags = [' #'+h for h in hashtags]\n",
    "        post.append ( ' '.join (hashtags))\n",
    "        post.append(data['url'])\n",
    "        post.append (emojis.emojis_selector(data['evaluation']))\n",
    "        \n",
    "        post.append (interjections (data['evaluation']))\n",
    "        \n",
    "        seed = random.randint(0,5)\n",
    "        if verify_post.verify_length(' '.join (post)):\n",
    "          post = post[:280]\n",
    "\n",
    "        \n",
    "        while (verify_post.verify_length(' '.join (post)) and seed > 0):\n",
    "                seed = seed - 1\n",
    "                post.append(emojis.emojis_selector(data['evaluation']))\n",
    "        \n",
    "\n",
    "        random.shuffle(post) \n",
    "\n",
    "        post = ' '.join(post)\n",
    "        \n",
    "        print(post)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df = pd.read_csv('snopes_posts_v3.csv')\n",
    "\n",
    "        row = {'id': data['id'], 'post': post}\n",
    "\n",
    "        # Adicionar a nova linha ao dataset\n",
    "        df = df.append(row,  ignore_index=True)\n",
    "\n",
    "        #Retirar colunaas que estão a mais\n",
    "        df = df[['id','post' ]]\n",
    "\n",
    "\n",
    "        df.to_csv('snopes_posts_v3.csv')\n",
    "            \n",
    "        print('--------------------------------------------')\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40cc5c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWITTERS BAN on former US President DONALD TRUMP was reversed in April 2022 by Elon MUSK hmph FALSE❗❗❗❗ 😭  #account  #rule  #rumor  #risk 😴 😡 🔫 😔 https://www.snopes.com/fact-check/musk-reinstate-trump-on-twitter/\n",
      "--------------------------------------------\n",
      "🔫 https://www.snopes.com/fact-check/nasa-mars-portal-door/ FALSE❗  wow A photograph captured by NASAS MARS CURIOSITY ROVER on May 7 2022 showed a PORTAL and a wall nearby that looks artificial 😪\n",
      "--------------------------------------------\n",
      " 💀 Karine JEANPIERRE once said FOX NEWS was RACIST before CORONAVIRUS They are RACIST during the CORONAVIRUS FOX NEWS will be RACIST after the CORONAVIRUS 😭 😭 CORRECT-ATTRIBUTION wow https://www.snopes.com/fact-check/jean-pierre-fox-news-racist/\n",
      "--------------------------------------------\n",
      "MISCAPTIONED 😩 😴 😞 wow https://www.snopes.com/fact-check/amber-heard-sniff-cocaine-trial/ 💀 😩 Actor AMBER Heard can be seen SNIFFING COCAINE from a tissue in a video of her TESTIMONY during a DEFAMATION trial brought by Johnny Depp  #cocaine  #nose  #testimony\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
